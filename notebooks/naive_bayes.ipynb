{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Entity Resolution using the Naive Bayes ML model\n",
    "\n",
    "We're going to dive into using the Naive Bayes regression model. This model\n",
    "is probabilistic in nature and can be trained to classify data in a given number\n",
    "of categories.\n",
    "The model is supervised, meaning that it learns using known good examples.\n",
    "Sounds like an ideal fit for entity resolution, right?\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "_(btw, the first parts of this code are the same as the Fellegi-Sunter example\n",
    "notebook, so check that one out, too)_.   "
   ],
   "id": "940700d100283c33"
  },
  {
   "cell_type": "code",
   "id": "ca31fd0d-16e8-4b69-ae32-3cfa3d13cd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:12:47.953594Z",
     "start_time": "2024-10-04T15:12:47.951487Z"
    }
   },
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from typing import Generator\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from matchescu.matching.entity_reference import EntityReferenceComparisonConfig, NaiveBayesComparison\n",
    "from matchescu.matching.ml.datasets import CsvDataSource, Traits"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, we need to define some fairly important 'constants' (alas, there's no such thing in Python).\n",
    "Feel free to change these values to whichever dataset you want to test."
   ],
   "id": "86ec9eb605aa9917"
  },
  {
   "cell_type": "code",
   "id": "ca59198f-45a6-48da-b119-b1e5d18d81a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:12:47.970809Z",
     "start_time": "2024-10-04T15:12:47.968680Z"
    }
   },
   "source": [
    "DATADIR = os.path.abspath(\"../../data\")\n",
    "LEFT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Abt.csv\")\n",
    "RIGHT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Buy.csv\")\n",
    "GROUND_TRUTH_PATH = os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The sources of information can be structured in any way. However, when we read\n",
    "from the data source we expect to be able to refer to discrete pieces of\n",
    "information.\n",
    "The important bit is to have a decent feature extraction process that is able to\n",
    "produce relatively uniformly shaped entity references. That's what `Traits()`\n",
    "do. That way we can get a neat matching process going.  "
   ],
   "id": "94a19e6978f60a76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:12:47.981506Z",
     "start_time": "2024-10-04T15:12:47.975261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up abt extraction\n",
    "abt_traits = list(Traits().int([0]).string([1, 2]).currency([3]))\n",
    "abt = CsvDataSource(name=\"abt\", traits=abt_traits).read_csv(LEFT_CSV_PATH)\n",
    "# set up buy extraction\n",
    "buy_traits = list(Traits().int([0]).string([1,2,3]).currency([4]))\n",
    "buy = CsvDataSource(name=\"buy\", traits=buy_traits).read_csv(RIGHT_CSV_PATH)\n",
    "# set up ground truth\n",
    "gt = set(pl.read_csv(os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\"), ignore_errors=True).iter_rows())"
   ],
   "id": "83b92f4b0ad5b632",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So far, this is very similar to the setup we had for the Fellegi-Sunter model.\n",
    "It's time to introduce the twist required to use the Naive Bayes model."
   ],
   "id": "7256f6f27121c8a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:12:47.984554Z",
     "start_time": "2024-10-04T15:12:47.982793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fs_config = NaiveBayesComparison().levenshtein(\n",
    "    \"name\", 1, 1, threshold=0.8\n",
    ").levenshtein(\n",
    "    \"description\", 2, 2, threshold=0.8\n",
    ").exact(\n",
    "    \"price\", 3, 4\n",
    ")"
   ],
   "id": "9a8c40f7a87a6ed5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you can see, the setup is still very similar to the Fellegi-Sunter model.\n",
    "We can even reuse our `RecordLinkageDataSet` to showcase the Naive Bayes model."
   ],
   "id": "f119313d74584337"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:14:25.795861Z",
     "start_time": "2024-10-04T15:12:47.985231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matchescu.matching.ml.datasets import RecordLinkageDataSet\n",
    "\n",
    "ds = RecordLinkageDataSet(abt, buy, gt)\n",
    "y = ds.target_vector.flatten()\n",
    "X = ds.compute_feature_matrix(fs_config)"
   ],
   "id": "fbeabd2e052f94d2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We just created the same type of feature matrix and target vector like the ones\n",
    "we had for the Fellegi-Sunter model.\n",
    "This time around, however, we need to pass them to SciKit Learn so we'll need\n",
    "all our data to be `numpy.ndarray`s.\n",
    "Also, the feature matrix values will be in the set `{-1, 1}`. "
   ],
   "id": "275e706feb9e71c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:14:25.848288Z",
     "start_time": "2024-10-04T15:14:25.797353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(\"match_pattern\").to_numpy(), y, train_size=0.6)\n",
    "y_ratio = len(y[y==1]) / len(y)\n",
    "y_train_ratio = len(y_train[y_train==1]) / len(y_train)\n",
    "y_test_ratio = len(y_test[y_test==1]) / len(y_test)\n",
    "print(y_ratio, y_train_ratio, y_test_ratio)"
   ],
   "id": "1937dd3ee913f9cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009293050458637878 0.0009445537089616828 0.0009064320673639982\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now train the Naive Bayes model that ships with SciKit learn.",
   "id": "71650989f15c1e09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:21:06.628177Z",
     "start_time": "2024-10-04T15:21:06.551189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model = model.fit(X_train, y_train)"
   ],
   "id": "e45a9e9214087a12",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Much easier than the Fellegi-Sunter method. Let's make predictions and compute\n",
    "precision, recall and the F1 score."
   ],
   "id": "f9d5564cdf5d97ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:21:09.520377Z",
     "start_time": "2024-10-04T15:21:09.482812Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred = model.predict(X_test)",
   "id": "41d5a203a0b3e7b2",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can compute our metrics.",
   "id": "18e713f96a0bbccb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:21:10.536476Z",
     "start_time": "2024-10-04T15:21:10.531057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tp = np.sum(np.logical_and(y_pred == 1, y_test == 1))\n",
    "fp = np.sum(np.logical_and(y_pred == 1, y_test == 0))\n",
    "tn = np.sum(np.logical_and(y_pred == 0, y_test == 0))\n",
    "fn = np.sum(np.logical_and(y_pred == 0, y_test == 1))\n",
    "total = len(y_test)\n",
    "print(f\"total comparisons: {total}\")\n",
    "print(f\"tp={tp};fp={fp};tn={tn};fn={fn}\")\n",
    "\n",
    "p = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "r = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "f1 = 2 * p * r / (p + r) if p + r > 0 else 0\n",
    "print(f\"precision={p}\", f\"recall={r}\", f\"F1={f1}\")"
   ],
   "id": "433106402b5eccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total comparisons: 472181\n",
      "tp=32;fp=135;tn=471618;fn=396\n",
      "precision=0.19161676646706588 recall=0.07476635514018691 F1=0.10756302521008403\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that this model isn't great either. But at least we didn't write much\n",
    "code and we have ways of improving our results. Polynomials and vectorization\n",
    "are two very common ideas. And, of course, we can try various probabilistic\n",
    "distributions. Since the training is so fast, we can actually find the best\n",
    "fit for our data by iterating over many options. We know full well that the\n",
    "resulting model is overfitted and won't transfer to other data, but at least\n",
    "we get a very tunable evaluator fairly quickly and easily. \n",
    "\n",
    "Before we get into the weeds, there's something obviously wrong with this model:\n",
    "it doesn't even capture the case when data is missing. So maybe a better way\n",
    "forward is to capture more information in each individual feature. That starts\n",
    "by having floating point values in the feature matrix.\n",
    "\n",
    "Enter logistic regression!"
   ],
   "id": "635b982829490e88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3555faf1a3b6a7d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
